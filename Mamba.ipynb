{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: PC\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def get_environment():\n",
    "    # Проверка на Google Colab\n",
    "    if 'COLAB_GPU' in os.environ:\n",
    "        return \"Colab\"\n",
    "    \n",
    "    # Проверка на Kaggle\n",
    "    elif 'KAGGLE_KERNEL_RUN_ID' in os.environ:\n",
    "        return \"Kaggle\"\n",
    "    \n",
    "    # Проверка на локальной машине\n",
    "    elif 'HOME' in os.environ or 'USERPROFILE' in os.environ:\n",
    "        return \"PC\"\n",
    "\n",
    "\n",
    "print(f\"Running on: {get_environment()}\")\n",
    "\n",
    "\n",
    "if get_environment() == 'PC':\n",
    "    PATH = os.getcwd()\n",
    "    DATA_PATH = '/mnt/c/TTS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo_text_processing.text_normalization.normalize import Normalizer\n",
    "from nemo.collections.tts.models import AlignerModel\n",
    "from nemo.collections.tts.torch.tts_tokenizers import EnglishPhonemesTokenizer\n",
    "from nemo.collections.tts.g2p.models.en_us_arpabet import EnglishG2p\n",
    "\n",
    "import math\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from einops import rearrange, repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " NeMo-text-processing :: INFO     :: Creating ClassifyFst grammars.\n",
      "[NeMo E 2024-11-28 17:45:35 en_us_arpabet:104] Torch distributed needs to be initialized before you initialized EnglishG2p. This class is prone to data access race conditions. Now downloading corpora from global rank 0. If other ranks pass this before rank 0, errors might result.\n",
      "[NeMo W 2024-11-28 17:45:35 en_us_arpabet:121] English g2p_dict will be used from nltk.corpus.cmudict.dict(), because phoneme_dict_path=None. Note that nltk.corpus.cmudict.dict() has old version (0.6) of CMUDict. You can use the latest official version of CMUDict (0.7b) with additional changes from NVIDIA directly from NeMo using the path scripts/tts_dataset_files/cmudict-0.7b_nv22.10.\n",
      "[NeMo W 2024-11-28 17:45:36 en_us_arpabet:66] apply_to_oov_word=None, This means that some of words will remain unchanged if they are not handled by any of the rules in self.parse_one_word(). This may be intended if phonemes and chars are both valid inputs, otherwise, you may see unexpected deletions in your input.\n"
     ]
    }
   ],
   "source": [
    "text_normalizer = Normalizer(input_case=\"cased\", lang=\"en\")\n",
    "arpabet_g2p = EnglishG2p(ignore_ambiguous_words=False)\n",
    "arpabet_tokenizer = EnglishPhonemesTokenizer(arpabet_g2p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-11-28 18:19:33 tts_tokenizers:656] Text: [WIY1 AA1R GOW1IH0NG TUW1 evaluat MAA1MBAH0 WAH1N] contains unknown char/phoneme: [e].Original text: [We are going to evaluat mamba one]. Symbol will be skipped.\n",
      "[NeMo W 2024-11-28 18:19:33 tts_tokenizers:656] Text: [WIY1 AA1R GOW1IH0NG TUW1 evaluat MAA1MBAH0 WAH1N] contains unknown char/phoneme: [v].Original text: [We are going to evaluat mamba one]. Symbol will be skipped.\n",
      "[NeMo W 2024-11-28 18:19:33 tts_tokenizers:656] Text: [WIY1 AA1R GOW1IH0NG TUW1 evaluat MAA1MBAH0 WAH1N] contains unknown char/phoneme: [a].Original text: [We are going to evaluat mamba one]. Symbol will be skipped.\n",
      "[NeMo W 2024-11-28 18:19:33 tts_tokenizers:656] Text: [WIY1 AA1R GOW1IH0NG TUW1 evaluat MAA1MBAH0 WAH1N] contains unknown char/phoneme: [l].Original text: [We are going to evaluat mamba one]. Symbol will be skipped.\n",
      "[NeMo W 2024-11-28 18:19:33 tts_tokenizers:656] Text: [WIY1 AA1R GOW1IH0NG TUW1 evaluat MAA1MBAH0 WAH1N] contains unknown char/phoneme: [u].Original text: [We are going to evaluat mamba one]. Symbol will be skipped.\n",
      "[NeMo W 2024-11-28 18:19:33 tts_tokenizers:656] Text: [WIY1 AA1R GOW1IH0NG TUW1 evaluat MAA1MBAH0 WAH1N] contains unknown char/phoneme: [a].Original text: [We are going to evaluat mamba one]. Symbol will be skipped.\n",
      "[NeMo W 2024-11-28 18:19:33 tts_tokenizers:656] Text: [WIY1 AA1R GOW1IH0NG TUW1 evaluat MAA1MBAH0 WAH1N] contains unknown char/phoneme: [t].Original text: [We are going to evaluat mamba one]. Symbol will be skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are going to evaluat mamba 1\n",
      "We are going to evaluat mamba one\n",
      "['W', 'IY1', ' ', 'AA1', 'R', ' ', 'G', 'OW1', 'IH0', 'NG', ' ', 'T', 'UW1', ' ', 'e', 'v', 'a', 'l', 'u', 'a', 't', ' ', 'M', 'AA1', 'M', 'B', 'AH0', ' ', 'W', 'AH1', 'N']\n",
      "[21, 35, 0, 25, 15, 0, 6, 36, 34, 13, 0, 18, 39, 0, 11, 25, 11, 1, 27, 0, 21, 27, 12]\n"
     ]
    }
   ],
   "source": [
    "text = \"We are going to evaluate mamba 1\"\n",
    "normalized_text = text_normalizer.normalize(text)\n",
    "arpabet_phonemes = arpabet_g2p(normalized_text)\n",
    "arpabet_tokens = arpabet_tokenizer(normalized_text)\n",
    "\n",
    "print(text)\n",
    "print(normalized_text)\n",
    "print(arpabet_phonemes)\n",
    "print(arpabet_tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
